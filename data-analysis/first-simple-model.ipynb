{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import proj1_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations of ML Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data:\n",
    "\n",
    "Testing data for helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([1, 2, 3, 4])\n",
    "tx = np.array([[1, 2, 3], \n",
    "               [4, 5, 6], \n",
    "               [7, 8, 9], \n",
    "               [10, 11, 12]])\n",
    "w = np.array([0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_mse(y, tx, w):\n",
    "    \"\"\"Calculate the MSE loss.\"\"\"\n",
    "    N = len(y)\n",
    "    e = y - np.dot(tx, w)\n",
    "    return np.dot(e,e) / (2 * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_mae(y, tx, w):\n",
    "    \"\"\"Calculate the MAE loss.\"\"\"\n",
    "    N = len(y)\n",
    "    e = y - np.dot(tx, w)\n",
    "    return np.sum(np.absolute(e)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_rmse(y, tx, w):\n",
    "    \"\"\"Computes the Root Mean Square Error\"\"\"\n",
    "    mse = compute_loss_mse(y, tx, w)\n",
    "    return np.sqrt(2 * mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_mse(y, tx, w):\n",
    "    \"\"\"Compute the MSE gradient.\"\"\"\n",
    "    N = len(y)\n",
    "    e = y - np.dot(tx, w)\n",
    "    return (-1/N) * np.dot(np.transpose(tx), e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stochastic_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a stochastic subgradient from just few examples n and their corresponding y_n labels.\"\"\"\n",
    "    N = len(y)\n",
    "    e = y - np.dot(tx, w)\n",
    "    abs_e_subgrad = [np.sign(en) for en in e] # Sign chosen for subgradient of absolute value function\n",
    "    return (-1/N) * np.dot(np.transpose(tx), abs_e_subgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate a minibatch iterator for a dataset.\n",
    "    Takes as input two iterables (here the output desired values 'y' and the input data 'tx')\n",
    "    Outputs an iterator which gives mini-batches of `batch_size` matching elements from `y` and `tx`.\n",
    "    Data can be randomly shuffled to avoid ordering in the original data messing with the randomness of the minibatches.\n",
    "    Example of use :\n",
    "    for minibatch_y, minibatch_tx in batch_iter(y, tx, 32):\n",
    "        <DO-SOMETHING>\n",
    "    \"\"\"\n",
    "    data_size = len(y)\n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "        shuffled_y = y[shuffle_indices]\n",
    "        shuffled_tx = tx[shuffle_indices]\n",
    "    else:\n",
    "        shuffled_y = y\n",
    "        shuffled_tx = tx\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_y[start_index:end_index], shuffled_tx[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing\n",
    "    \"\"\"\n",
    "    np.random.seed(seed) # set seed\n",
    "    permuted_idxs = np.random.permutation(x.shape[0])\n",
    "    train_size = int(ratio * x.shape[0])\n",
    "    train_idxs, test_idxs = permuted_idxs[:train_size], permuted_idxs[train_size:]\n",
    "    \n",
    "    return x[train_idxs], x[test_idxs], y[train_idxs], y[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to implement for project 1 submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Linear regression using gradient descent\"\"\"\n",
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"Gradient descent algorithm using MSE.\"\"\"\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        grad = compute_gradient_mse(y, tx, w)\n",
    "        loss = compute_loss_mse(y, tx, w)\n",
    "        w = w - gamma * grad\n",
    "        \n",
    "    rmse = compute_rmse(y, tx, w)\n",
    "\n",
    "    return w, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Linear regression using stochastic gradient descent\"\"\"\n",
    "def stochastic_subgradient_descent_mae(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"Stochastic subgradient descent algorithm using MAE.\"\"\"\n",
    "    batch_size = 1\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            g = compute_stochastic_subgradient_mae(minibatch_y, minibatch_tx, w)\n",
    "            w = w - gamma * g\n",
    "        loss = compute_loss_mae(y, tx, w)\n",
    "        print(\"Stochastic Subgradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"Calculates the explicit least squares solution.\n",
    "    Returns rmse, optimal weights\"\"\"\n",
    "    N = tx.shape[0]\n",
    "    D = tx.shape[1]\n",
    "    rank_tx = np.linalg.matrix_rank(tx)\n",
    "    \n",
    "    # Check if tx is invertible. If so, find explicit solution\n",
    "    # using real inverses.\n",
    "    # If not, find explicit solution using pseudoinverses.\n",
    "    if (rank_tx == max(tx.shape[0], tx.shape[1])):\n",
    "        gramian_inv = np.linalg.inv(np.dot(tx.T, tx))\n",
    "        w = np.dot(gramian_inv, np.dot(tx.T, y))\n",
    "    else:\n",
    "        U, s, V_T = np.linalg.svd(tx)\n",
    "        S_inv_T = np.zeros((D, N))\n",
    "        S_inv_T[:len(s), :len(s)] = np.diag(1/s)\n",
    "        w = np.dot(V_T.T, np.dot(S_inv_T, np.dot(U.T, y)))\n",
    "    \n",
    "    rmse = compute_rmse(y, tx, w)\n",
    "    \n",
    "    return w, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"Ridge regression using normal equations\"\"\"\n",
    "    \n",
    "    #if (lambda_ == 0):\n",
    "    #    return least_squares(y, tx)\n",
    "    \n",
    "    N = tx.shape[0]\n",
    "    D = tx.shape[1]\n",
    "    \n",
    "    inv = np.linalg.inv(np.dot(tx.T, tx) + 2 * N * lambda_ * np.identity(D))\n",
    "    w = np.dot(inv, np.dot(tx.T, y))\n",
    "    \n",
    "    rmse = compute_rmse(y, tx, w)\n",
    "    \n",
    "    return w, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Logistic regression using gradient descent or SGD\"\"\"\n",
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Regularized logistic regression using gradient descent or SGD\"\"\"\n",
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higgs Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental functions\n",
    "\n",
    "All of these functions can be used experimentally to, in one way or the other, improve the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correctness(yb, y_pred):\n",
    "    \"\"\"Takes inputs known y and predicted y and prints the ratio of correct predictions vs incorrect ones.\"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if (y_pred[i] == yb[i]):\n",
    "            correct += 1\n",
    "        \n",
    "    incorrect = len(y_pred) - correct\n",
    "    perc = correct / len(y_pred) * 100\n",
    "    print(\"Total correct:\", correct, \"\\nTotal incorrect:\", incorrect, \"\\nCorrect percentage:\", perc, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_nan_by_mean(tx, nan_value):\n",
    "    \"\"\"Replaces values with a specified nan_value by the column mean.\"\"\"\n",
    "    tx[tx == nan_value] = np.nan\n",
    "    col_mean = np.nanmean(tx, axis=0)\n",
    "    return np.where(np.isnan(tx), col_mean, tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_nan_by_median(tx, nan_value):\n",
    "    \"\"\"Replaces values with a specified nan_value by the column median.\"\"\"\n",
    "    tx[tx == nan_value] = np.nan\n",
    "    col_median = np.nanmedian(tx, axis=0)\n",
    "    return np.where(np.isnan(tx), col_median, tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_nan_rows(tx, nan_value):\n",
    "    \"\"\"Drop all rows that contain a nan equaling the specified nan_value.\"\"\"\n",
    "    tx[tx == nan_value] = np.nan\n",
    "    return tx[~np.isnan(tx).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_simple_poly(tx, degree):\n",
    "    \"\"\"\n",
    "    Builds simple polynomial basis function for input data matrix tx, for j=0 up to j=degree,\n",
    "    where the result will be a matrix of form [1, tx, tx^2, ..., tx^j].\n",
    "    tx^j denotes that for each x_i,k in tx, the result will be (x_i,k)^j\n",
    "    \"\"\"\n",
    "    poly = np.ones((tx.shape[0], 1))\n",
    "\n",
    "    for j in range(1, degree+1):\n",
    "        poly = np.column_stack((poly, np.power(tx, j)))\n",
    "\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# TODO: Optimize. Very slow!\n",
    "def build_mult_comb(tx, deg, cols=[]):\n",
    "    \"\"\"\n",
    "    Returns all multiplicative combinations of the specified columns for degree deg.\n",
    "    For len(col) = D', there are (D' choose deg) combinations of columns that get\n",
    "    returned as a matrix.\n",
    "    If cols is not given, it returns the combinations of all columns of tx.\n",
    "    \"\"\"\n",
    "    N = tx.shape[0]\n",
    "    if (cols == []):\n",
    "        comb_iter = itertools.combinations_with_replacement(range(tx.shape[1]), deg)\n",
    "    else:\n",
    "        comb_iter = itertools.combinations_with_replacement(cols, deg)\n",
    "    mult = []\n",
    "    for comb in comb_iter:\n",
    "        mult_col = np.ones(N)\n",
    "        for idx in comb:\n",
    "            tx_col = tx[:,idx]\n",
    "            mult_col = np.multiply(mult_col, tx_col)\n",
    "        mult.append(mult_col.tolist())\n",
    "    return np.array(mult).T\n",
    "\n",
    "def build_advanced_poly(tx, degree, cols=[]):\n",
    "    \"\"\"\n",
    "    Builds full polynomial basis function for input data matrix tx, for j=0 up to j=degree,\n",
    "    where the result will be a matrix of form:\n",
    "    [1, tx, comb_mult(tx, 2), ..., comb_mult(tx, j)]\n",
    "    comb_mult(tx, 2) denotes all multiplicative combinations of the selected columns of tx.\n",
    "    If cols is not given, it returns the combinations of all columns of tx.\n",
    "    \"\"\"\n",
    "    poly = np.ones((tx.shape[0], 1))\n",
    "\n",
    "    for j in range(1, degree+1):\n",
    "        mult = build_mult_comb(tx, j, cols)\n",
    "        poly = np.column_stack((poly, mult))\n",
    "\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "data_path = \"../data/train.csv\"\n",
    "yb, input_data, ids = load_csv_data(data_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data to more useable data, by replacing NaN's by the column mean and creating a polynomial base expansion.\n",
    "\n",
    "By previous data analysis, important_cols are selected to be the few \"most influencial\" features. We use only those few weights in the polynomial base expansion for computational efficiency.\n",
    "\n",
    "| Index | Feature                   |\n",
    "|-------|---------------------------|\n",
    "|  0    | DER_mass_MMC              |\n",
    "| 1     | DER_mass_traverse_met_lep |\n",
    "| 2     | DER_mass_vis              |\n",
    "| 13    | PRI_tau_pt                |\n",
    "| 11    | DER_met_phi_centrality    |\n",
    "| 10    | DER_pt_ratio_lep_tau      |\n",
    "| 7     | DER_deltar_tau_lep        |\n",
    "| 19    | PRI_met                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = replace_nan_by_median(input_data, -999)\n",
    "\n",
    "important_cols = [0, 1, 2, 7, 10, 11, 13, 19]\n",
    "degree = 2 # With current implementation, higher than 5 is comp. infeasable, but it gives the best results!\n",
    "\n",
    "x_poly = build_advanced_poly(input_data, degree, important_cols)\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(x_poly, yb, ratio=0.9, seed=123456789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.000010000, Training RMSE=0.807, Testing RMSE=0.804\n",
      "lambda=0.000022758, Training RMSE=0.807, Testing RMSE=0.804\n",
      "lambda=0.000051795, Training RMSE=0.807, Testing RMSE=0.804\n",
      "lambda=0.000117877, Training RMSE=0.807, Testing RMSE=0.805\n",
      "lambda=0.000268270, Training RMSE=0.807, Testing RMSE=0.805\n",
      "lambda=0.000610540, Training RMSE=0.808, Testing RMSE=0.807\n",
      "lambda=0.001389495, Training RMSE=0.810, Testing RMSE=0.809\n",
      "lambda=0.003162278, Training RMSE=0.812, Testing RMSE=0.811\n",
      "lambda=0.007196857, Training RMSE=0.815, Testing RMSE=0.815\n",
      "lambda=0.016378937, Training RMSE=0.819, Testing RMSE=0.819\n",
      "lambda=0.037275937, Training RMSE=0.823, Testing RMSE=0.824\n",
      "lambda=0.084834290, Training RMSE=0.827, Testing RMSE=0.828\n",
      "lambda=0.193069773, Training RMSE=0.829, Testing RMSE=0.830\n",
      "lambda=0.439397056, Training RMSE=0.831, Testing RMSE=0.832\n",
      "lambda=1.000000000, Training RMSE=0.832, Testing RMSE=0.833\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEaCAYAAAA7YdFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11353ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plots import *\n",
    "\n",
    "# Experiment to find best lambda\n",
    "def ridge_regression_demo():\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        weights, rmse = ridge_regression(y_train, x_train, lambda_)\n",
    "        rmse_tr.append(compute_rmse(y_train, x_train, weights))\n",
    "        rmse_te.append(compute_rmse(y_test, x_test, weights))\n",
    "        \n",
    "        print(\"lambda={l:.9f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "               l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "        \n",
    "    # Plot the obtained results\n",
    "    plot_train_test(rmse_tr, rmse_te, lambdas, 2)\n",
    "    \n",
    "ridge_regression_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in best lambda from above and get weights\n",
    "weights, rmse = ridge_regression(y_train, x_train, lambda_=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 192475 \n",
      "Total incorrect: 57525 \n",
      "Correct percentage: 76.99000000000001 %\n",
      "-----------------------------\n",
      "Train RMSE: 0.806750582846 , Test RMSE: 0.80393570686\n"
     ]
    }
   ],
   "source": [
    "# Predict labels with found weights and print some useful information about quality of fit\n",
    "y_pred = predict_labels(weights, x_poly)\n",
    "correctness(yb, y_pred)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "rmse_train = compute_rmse(y_train, x_train, weights)\n",
    "rmse_test = compute_rmse(y_test, x_test, weights)\n",
    "print(\"Train RMSE:\", rmse_train, \", Test RMSE:\", rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and transform test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = \"../data/test.csv\"\n",
    "yb_test, input_data_test, ids_test = load_csv_data(test_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data_test = replace_nan_by_median(input_data_test, -999)\n",
    "x_submit_poly = build_advanced_poly(input_data_test, degree, important_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = predict_labels(weights, x_submit_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions of test data in csv file, ready for the upload on kaggle\n",
    "create_csv_submission(ids_test, y_test_pred, \"test_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
