{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from mlcomp.config import DATA_PATH\n",
    "from mlcomp.data import load_csv_data\n",
    "from mlcomp.helpers import split_data\n",
    "from mlcomp.costs import compute_correctness, compute_mae, compute_mse\n",
    "from mlcomp.cross_validation import ridge_lambda_cv, get_best_parameter\n",
    "from mlcomp.performance import predict_values, predict\n",
    "from mlcomp.models import ridge_regression\n",
    "from mlcomp.feature_eng import build_simple_poly, replace_nan_by_median, build_advanced_poly\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "RATIO_SPLIT = 0.3\n",
    "SEED_SPLIT = 872\n",
    "LAMBDA_SPACE = np.logspace(-5, 0, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X, ids = load_csv_data(TRAIN_PATH)\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, RATIO_SPLIT, seed=SEED_SPLIT)\n",
    "col_names = list(np.genfromtxt(TRAIN_PATH, delimiter=\",\", dtype=None,  max_rows=1))\n",
    "col_names = list(map(lambda x: x.decode(\"utf-8\"), col_names))[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_advanced_poly(X, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummyrize(X, col_index, allowed_values):\n",
    "    X_plus = copy.deepcopy(X)\n",
    "    col_to_dummy = X[: , col_index-1]\n",
    "    dummies = np.empty((len(X_plus), len(allowed_values)-1))\n",
    "    \n",
    "    for i, v in enumerate(allowed_values[0:-1]):\n",
    "        dummies[:, i] = (col_to_dummy == v)*1\n",
    "    \n",
    "    return np.delete(np.concatenate((X_plus, dummies), axis=1), [col_index-2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_transformations(X):\n",
    "    N = len(X)\n",
    "    \n",
    "    # abs\n",
    "    cols_to_abs = [14, # PRI_tau_eta\n",
    "                   17, # PRI_lep_eta\n",
    "                   24, # PRI_jet_leading_eta\n",
    "                   27, # PRI_jet_subleading_eta\n",
    "                  ] \n",
    "    abs_cols = []\n",
    "    for c in cols_to_abs:\n",
    "        abs_cols.append((abs(X[:, c])).reshape((N, 1)))\n",
    "        \n",
    "    # abs of difference\n",
    "    cols_to_abs_diff = [(14, 17), (14, 24), (14, 27),\n",
    "                        (17, 24), (17, 27),\n",
    "                        (24, 27)]\n",
    "    abs_diff_cols = []\n",
    "    for c1, c2 in cols_to_abs_diff:\n",
    "        abs_diff_cols.append((abs(X[:, c1] - X[:, c2])).reshape(N, 1))\n",
    "        \n",
    "    # interactions\n",
    "    cols_to_interaction = [(14, 17), (14, 24), (14, 27),\n",
    "                           (17, 24), (17, 27),\n",
    "                           (24, 27)]\n",
    "    interaction_cols = []\n",
    "    for c1, c2 in cols_to_interaction:\n",
    "        interaction_cols.append((X[:, c1]*X[:, c2]).reshape(N, 1))\n",
    "        \n",
    "    deltaphi_tau_lep = np.where(X[:, 15]-X[:, 18]<np.pi, X[:, 15]-X[:, 18], 2*np.pi-X[:, 15]-X[:, 18]).reshape(N,1)\n",
    "    deltaphi_tau_jet1 = np.where(X[:, 15]-X[:, 25]<np.pi, X[:, 15]-X[:, 25], 2*np.pi-X[:, 15]-X[:, 25]).reshape(N,1)\n",
    "    deltaphi_tau_jet2 = np.where(X[:, 15]-X[:, 28]<np.pi, X[:, 15]-X[:, 28], 2*np.pi-X[:, 15]-X[:, 28]).reshape(N,1)\n",
    "    deltaphi_lep_jet1 = np.where(X[:, 18]-X[:, 25]<np.pi, X[:, 18]-X[:, 25], 2*np.pi-X[:, 18]-X[:, 25]).reshape(N,1)\n",
    "    deltaphi_lep_jet2 = np.where(X[:, 18]-X[:, 28]<np.pi, X[:, 18]-X[:, 28], 2*np.pi-X[:, 18]-X[:, 28]).reshape(N,1)\n",
    "    deltaphi_jet_jet = np.where(X[:, 25]-X[:, 28]<np.pi, X[:, 25]-X[:, 28], 2*np.pi-X[:, 25]-X[:, 28]).reshape(N,1)\n",
    "    \n",
    "    distance_cols = []\n",
    "    distance_cols.append(np.sqrt(np.square(abs(X[:, 14]-X[:, 17]).reshape(N,1))+np.square(deltaphi_tau_lep)))\n",
    "    distance_cols.append(np.sqrt(np.square(abs(X[:, 14]-X[:, 24]).reshape(N,1))+np.square(deltaphi_tau_jet1)))\n",
    "    distance_cols.append(np.sqrt(np.square(abs(X[:, 14]-X[:, 27]).reshape(N,1))+np.square(deltaphi_tau_jet2)))\n",
    "    distance_cols.append(np.sqrt(np.square(abs(X[:, 17]-X[:, 24]).reshape(N,1))+np.square(deltaphi_lep_jet1)))\n",
    "    distance_cols.append(np.sqrt(np.square(abs(X[:, 17]-X[:, 27]).reshape(N,1))+np.square(deltaphi_lep_jet2)))\n",
    "    distance_cols.append(np.sqrt(np.square(abs(X[:, 24]-X[:, 27]).reshape(N,1))+np.square(deltaphi_jet_jet)))\n",
    "    d = (X[:, 15] - X[:, 18]).reshape(N,1)\n",
    "    d = 1.0 - 2.0*((d>np.pi)|((d<0) & (d>-np.pi)))\n",
    "    a = np.sin(X[:, 20]-X[:, 18]).reshape(N,1)\n",
    "    b = np.sin(X[:, 15]-X[:, 20]).reshape(N,1)\n",
    "    distance_cols.append(d*(a+b)/np.sqrt(np.square(a)+np.square(b)).reshape(N,1))\n",
    "#     list_transf.append(np.exp(-4.0*np.square(X[:, 17]-(X[:, 24]+X[:, 27])/2).reshape(N,1)/np.square(X[:, 24]-X[:, 27]).reshape(N,1)))\n",
    "#     list_transf.append(np.exp(-4.0*np.square(X[:, 24]-(X[:, 24]+X[:, 27])/2).reshape(N,1)/np.square(X[:, 24]-X[:, 27]).reshape(N,1)))\n",
    "\n",
    "    cols_to_metric = [(19, 20, 13, 15), (19, 20, 16, 18), (19, 20, 23, 25), (19, 20, 26, 28),\n",
    "                      (13, 15, 16, 18), (13, 15, 16, 18), (13, 15, 23, 25), (13, 15, 26, 28), \n",
    "                      (16, 18, 23, 25), (16, 18, 26, 28), (23, 25, 26, 28)]\n",
    "    metric_cols = []\n",
    "    for c1, c2, c3, c4 in cols_to_metric:\n",
    "        m = (np.square(X[:, c1]*np.cos(X[:, c2]) + X[:, c3]*np.cos(X[:, c4]))\n",
    "        + np.square(X[:, c1]*np.sin(X[:, c2]) + X[:, c3]*np.sin(X[:, c4]))).reshape(N,1)\n",
    "        metric_cols.append(m)\n",
    "        \n",
    "    metric_to_mass = [(19, 13, 0), (19, 16, 1), (19, 23, 2), (19, 26, 3), \n",
    "                    (13, 16, 4), (13, 23, 5), (13, 26, 6),\n",
    "                    (16, 23, 7), (16, 26, 8), \n",
    "                    (23, 26, 9)]\n",
    "    metric2_cols = []\n",
    "    for c1, c2, c3 in metric_to_mass:\n",
    "        m = np.sqrt(abs(np.square((X[:, 19]+X[:, 13]).reshape(N,1))-metric_cols[c3]))\n",
    "        metric2_cols.append(m)\n",
    "        \n",
    "    cols_to_p2 = [(4, 13, 14, 16, 17), (5, 13, 14, 23, 24), (6, 13, 14, 26, 27),\n",
    "                  (7, 16, 17, 23, 24), (8, 16, 17, 26, 27),\n",
    "                  (9, 23, 24, 26, 27)]\n",
    "    p2_cols = []\n",
    "    for c1, c2, c3, c4, c5 in cols_to_p2:\n",
    "        m = (metric_cols[c1] + (np.square(X[:, c2]*np.square(X[:, c3])).reshape(N,1) + (X[:, c4]*np.sinh(X[:, c5])).reshape(N,1))).reshape(N,1)\n",
    "        p2_cols.append(m)\n",
    "        \n",
    "    cosh_to_cols = [(13, 14), (16, 17), (23, 24), (26, 27)]\n",
    "    cosh_cols = []\n",
    "    for c1, c2 in cosh_to_cols:\n",
    "        m = (X[:, c1]*np.cosh(X[:, c2])).reshape(N,1)\n",
    "        cosh_cols.append(m)\n",
    "        \n",
    "    cols_to_mass = [(0, 1, 0), (0, 2, 1), (0, 3, 2), (1, 2, 3), (1, 3, 4), (2, 3, 5)]\n",
    "    mass_cols = []\n",
    "    for c1, c2, c3 in cols_to_mass:\n",
    "        m = np.sqrt((np.square(abs((cosh_cols[c1]+cosh_cols[c2]).reshape(N,1))-p2_cols[c3]))).reshape(N,1)\n",
    "        mass_cols.append(m)\n",
    "        \n",
    "    s_px = (X[:, 19]*np.cos(X[:, 20]) + X[:, 13]*np.cos(X[:, 15]) + X[:, 16]*np.cos(X[:, 18])).reshape(N,1)\n",
    "    s_py = (X[:, 19]*np.sin(X[:, 20]) + X[:, 13]*np.sin(X[:, 15]) + X[:, 16]*np.sin(X[:, 18])).reshape(N,1)\n",
    "    distance_cols.append(np.sqrt(np.square(s_px) + np.square(s_py)).reshape(N,1))\n",
    "    \n",
    "    s_px_2 = s_px + (X[:, 23]*np.cos(X[:, 25])).reshape(N,1)\n",
    "    s_px_2[np.isnan(s_px_2)] = 0\n",
    "    s_py_2 = s_py + (X[:, 23]*np.sin(X[:, 25])).reshape(N,1)\n",
    "    s_py_2[np.isnan(s_py_2)] = 0\n",
    "    distance_cols.append(np.sqrt(np.square(s_px_2) + np.square(s_py_2)).reshape(N,1))  \n",
    "    \n",
    "    s_px_3 = s_px_2 + (X[:, 26]*np.cos(X[:, 28])).reshape(N,1)\n",
    "    s_px_3[np.isnan(s_px_3)] = 0\n",
    "    s_py_3 = s_py_2 + (X[:, 26]*np.sin(X[:, 28])).reshape(N,1)\n",
    "    s_py_3[np.isnan(s_py_3)] = 0\n",
    "    distance_cols.append(np.sqrt(np.square(s_px_3) + np.square(s_py_3)).reshape(N,1))\n",
    "    \n",
    "    sums_cols = []\n",
    "    sums_cols.append((X[:, 19] + X[:, 13] + X[:, 16]).reshape(N,1))\n",
    "    sums_cols.append((sums_cols[0] + X[:, 23].reshape(N,1)).reshape(N,1))\n",
    "#     sums_cols.append((sums_cols[1] + X[:, 26].reshape(N,1)).reshape(N,1))\n",
    "#     sums_cols.append((sums_cols[1] + X[:, 29].reshape(N,1)).reshape(N,1))\n",
    "    sums_cols.append((X[:, 13] + X[:, 16] + X[:, 29]).reshape(N,1))\n",
    "    \n",
    "    ratio_cols = []\n",
    "    ratio_cols.append((X[:, 16]/X[:, 13]).reshape(N,1))\n",
    "    \n",
    "    \n",
    "    valid_transformations = [abs_cols, \n",
    "                             abs_diff_cols,\n",
    "                             interaction_cols, \n",
    "                             distance_cols, \n",
    "                             metric_cols, \n",
    "                             metric2_cols, \n",
    "                             p2_cols, \n",
    "                             mass_cols,\n",
    "                             sums_cols,\n",
    "                             ratio_cols\n",
    "#                              cosh_cols\n",
    "                            ]\n",
    "    transformations = [item for sublist in valid_transformations for item in sublist]\n",
    "\n",
    "    array_transf = np.hstack(transformations)\n",
    "    \n",
    "    return np.concatenate((X, array_transf), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 94)\n",
      "Best lambda: 1e-05\n",
      "Performance in test set: 76.463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.138689041137695"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "def apply_feature_eng(X):\n",
    "\n",
    "    X_plus = copy.deepcopy(X)\n",
    "    \n",
    "    X_plus = replace_nan_by_median(X, -999)\n",
    "    \n",
    "    X_plus = new_transformations(X_plus)\n",
    "    \n",
    "    X_plus = (X_plus - X_plus.mean(axis=0)) / X_plus.std(axis=0)\n",
    "   \n",
    "    X_plus = build_simple_poly(X_plus, 1)\n",
    "    \n",
    "#     dummy_cols = {'PRI_jet_num': [1, 2, 3, 4]}\n",
    "#     for c in dummy_cols:\n",
    "#         X_plus = dummyrize(X_plus, col_names.index(c), dummy_cols[c]) # decrese performance \n",
    "    \n",
    "     \n",
    "    return X_plus\n",
    "\n",
    "X_feat = apply_feature_eng(X)\n",
    "print(X_feat.shape)\n",
    "X_feat_train = apply_feature_eng(X_train)\n",
    "X_feat_test = apply_feature_eng(X_test)\n",
    "\n",
    "LOSS_FN = compute_correctness\n",
    "LOSS_GREATER_IS_BETTER = True\n",
    "\n",
    "loss_test = ridge_lambda_cv(y_train, X_feat_train, compute_correctness, LAMBDA_SPACE)[1]\n",
    "best_lambda = get_best_parameter(loss_test, LAMBDA_SPACE, LOSS_GREATER_IS_BETTER)\n",
    "\n",
    "best_w = ridge_regression(y, X_feat, best_lambda)\n",
    "y_test_values = predict_values(best_w, X_feat_test)\n",
    "y_hat_test = predict(y_test_values, 0)\n",
    "performance_test = compute_correctness(y_test, y_hat_test)\n",
    "\n",
    "print('Best lambda: {lambda_}\\nPerformance in test set: {pf_test}'\n",
    "      .format(lambda_=best_lambda, pf_test=round(performance_test, 3)))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 187)\n",
      "Best lambda: 2.21221629107045e-05\n",
      "Performance in test set: 78.078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.99583911895752"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "def apply_feature_eng(X):\n",
    "\n",
    "    X_plus = copy.deepcopy(X)\n",
    "    \n",
    "    X_plus = replace_nan_by_median(X, -999)\n",
    "    \n",
    "    X_plus = new_transformations(X_plus)\n",
    "    \n",
    "    X_plus = (X_plus - X_plus.mean(axis=0)) / X_plus.std(axis=0)\n",
    "   \n",
    "    X_plus = build_simple_poly(X_plus, 2)\n",
    "    \n",
    "#     dummy_cols = {'PRI_jet_num': [1, 2, 3, 4]}\n",
    "#     for c in dummy_cols:\n",
    "#         X_plus = dummyrize(X_plus, col_names.index(c), dummy_cols[c]) # decrese performance \n",
    "    \n",
    "     \n",
    "    return X_plus\n",
    "\n",
    "X_feat = apply_feature_eng(X)\n",
    "print(X_feat.shape)\n",
    "X_feat_train = apply_feature_eng(X_train)\n",
    "X_feat_test = apply_feature_eng(X_test)\n",
    "\n",
    "LOSS_FN = compute_correctness\n",
    "LOSS_GREATER_IS_BETTER = True\n",
    "\n",
    "loss_test = ridge_lambda_cv(y_train, X_feat_train, compute_correctness, LAMBDA_SPACE)[1]\n",
    "best_lambda = get_best_parameter(loss_test, LAMBDA_SPACE, LOSS_GREATER_IS_BETTER)\n",
    "\n",
    "best_w = ridge_regression(y, X_feat, best_lambda)\n",
    "y_test_values = predict_values(best_w, X_feat_test)\n",
    "y_hat_test = predict(y_test_values, 0)\n",
    "performance_test = compute_correctness(y_test, y_hat_test)\n",
    "\n",
    "print('Best lambda: {lambda_}\\nPerformance in test set: {pf_test}'\n",
    "      .format(lambda_=best_lambda, pf_test=round(performance_test, 3)))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 280)\n",
      "Best lambda: 0.001743328822199989\n",
      "Performance in test set: 79.088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.662065982818604"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "def apply_feature_eng(X):\n",
    "\n",
    "    X_plus = copy.deepcopy(X)\n",
    "    \n",
    "    X_plus = replace_nan_by_median(X, -999)\n",
    "    \n",
    "    X_plus = new_transformations(X_plus)\n",
    "    \n",
    "    X_plus = (X_plus - X_plus.mean(axis=0)) / X_plus.std(axis=0)\n",
    "   \n",
    "    X_plus = build_simple_poly(X_plus, 3)\n",
    "    \n",
    "#     dummy_cols = {'PRI_jet_num': [1, 2, 3, 4]}\n",
    "#     for c in dummy_cols:\n",
    "#         X_plus = dummyrize(X_plus, col_names.index(c), dummy_cols[c]) # decrese performance \n",
    "    \n",
    "     \n",
    "    return X_plus\n",
    "\n",
    "X_feat = apply_feature_eng(X)\n",
    "print(X_feat.shape)\n",
    "X_feat_train = apply_feature_eng(X_train)\n",
    "X_feat_test = apply_feature_eng(X_test)\n",
    "\n",
    "LOSS_FN = compute_correctness\n",
    "LOSS_GREATER_IS_BETTER = True\n",
    "\n",
    "loss_test = ridge_lambda_cv(y_train, X_feat_train, compute_correctness, LAMBDA_SPACE)[1]\n",
    "best_lambda = get_best_parameter(loss_test, LAMBDA_SPACE, LOSS_GREATER_IS_BETTER)\n",
    "\n",
    "best_w = ridge_regression(y, X_feat, best_lambda)\n",
    "y_test_values = predict_values(best_w, X_feat_test)\n",
    "y_hat_test = predict(y_test_values, 0)\n",
    "performance_test = compute_correctness(y_test, y_hat_test)\n",
    "\n",
    "print('Best lambda: {lambda_}\\nPerformance in test set: {pf_test}'\n",
    "      .format(lambda_=best_lambda, pf_test=round(performance_test, 3)))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 373)\n",
      "Best lambda: 1e-05\n",
      "Performance in test set: 79.773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.98775792121887"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "def apply_feature_eng(X):\n",
    "\n",
    "    X_plus = copy.deepcopy(X)\n",
    "    \n",
    "    X_plus = replace_nan_by_median(X, -999)\n",
    "    \n",
    "    X_plus = new_transformations(X_plus)\n",
    "    \n",
    "    X_plus = (X_plus - X_plus.mean(axis=0)) / X_plus.std(axis=0)\n",
    "   \n",
    "    X_plus = build_simple_poly(X_plus, 4)\n",
    "    \n",
    "#     dummy_cols = {'PRI_jet_num': [1, 2, 3, 4]}\n",
    "#     for c in dummy_cols:\n",
    "#         X_plus = dummyrize(X_plus, col_names.index(c), dummy_cols[c]) # decrese performance \n",
    "    \n",
    "     \n",
    "    return X_plus\n",
    "\n",
    "X_feat = apply_feature_eng(X)\n",
    "print(X_feat.shape)\n",
    "X_feat_train = apply_feature_eng(X_train)\n",
    "X_feat_test = apply_feature_eng(X_test)\n",
    "\n",
    "LOSS_FN = compute_correctness\n",
    "LOSS_GREATER_IS_BETTER = True\n",
    "\n",
    "loss_test = ridge_lambda_cv(y_train, X_feat_train, compute_correctness, LAMBDA_SPACE)[1]\n",
    "best_lambda = get_best_parameter(loss_test, LAMBDA_SPACE, LOSS_GREATER_IS_BETTER)\n",
    "\n",
    "best_w = ridge_regression(y, X_feat, best_lambda)\n",
    "y_test_values = predict_values(best_w, X_feat_test)\n",
    "y_hat_test = predict(y_test_values, 0)\n",
    "performance_test = compute_correctness(y_test, y_hat_test)\n",
    "\n",
    "print('Best lambda: {lambda_}\\nPerformance in test set: {pf_test}'\n",
    "      .format(lambda_=best_lambda, pf_test=round(performance_test, 3)))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 466)\n",
      "Best lambda: 0.018873918221350976\n",
      "Performance in test set: 79.73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58.937978982925415"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "def apply_feature_eng(X):\n",
    "\n",
    "    X_plus = copy.deepcopy(X)\n",
    "    \n",
    "    X_plus = replace_nan_by_median(X, -999)\n",
    "    \n",
    "    X_plus = new_transformations(X_plus)\n",
    "    \n",
    "    X_plus = (X_plus - X_plus.mean(axis=0)) / X_plus.std(axis=0)\n",
    "   \n",
    "    X_plus = build_simple_poly(X_plus, 5)\n",
    "    \n",
    "#     dummy_cols = {'PRI_jet_num': [1, 2, 3, 4]}\n",
    "#     for c in dummy_cols:\n",
    "#         X_plus = dummyrize(X_plus, col_names.index(c), dummy_cols[c]) # decrese performance \n",
    "    \n",
    "     \n",
    "    return X_plus\n",
    "\n",
    "X_feat = apply_feature_eng(X)\n",
    "print(X_feat.shape)\n",
    "X_feat_train = apply_feature_eng(X_train)\n",
    "X_feat_test = apply_feature_eng(X_test)\n",
    "\n",
    "LOSS_FN = compute_correctness\n",
    "LOSS_GREATER_IS_BETTER = True\n",
    "\n",
    "loss_test = ridge_lambda_cv(y_train, X_feat_train, compute_correctness, LAMBDA_SPACE)[1]\n",
    "best_lambda = get_best_parameter(loss_test, LAMBDA_SPACE, LOSS_GREATER_IS_BETTER)\n",
    "\n",
    "best_w = ridge_regression(y, X_feat, best_lambda)\n",
    "y_test_values = predict_values(best_w, X_feat_test)\n",
    "y_hat_test = predict(y_test_values, 0)\n",
    "performance_test = compute_correctness(y_test, y_hat_test)\n",
    "\n",
    "print('Best lambda: {lambda_}\\nPerformance in test set: {pf_test}'\n",
    "      .format(lambda_=best_lambda, pf_test=round(performance_test, 3)))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 559)\n",
      "Best lambda: 0.06210169418915616\n",
      "Performance in test set: 50.108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.06282377243042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "def apply_feature_eng(X):\n",
    "\n",
    "    X_plus = copy.deepcopy(X)\n",
    "    \n",
    "    X_plus = replace_nan_by_median(X, -999)\n",
    "    \n",
    "    X_plus = new_transformations(X_plus)\n",
    "    \n",
    "    X_plus = (X_plus - X_plus.mean(axis=0)) / X_plus.std(axis=0)\n",
    "   \n",
    "    X_plus = build_simple_poly(X_plus, 6)\n",
    "    \n",
    "#     dummy_cols = {'PRI_jet_num': [1, 2, 3, 4]}\n",
    "#     for c in dummy_cols:\n",
    "#         X_plus = dummyrize(X_plus, col_names.index(c), dummy_cols[c]) # decrese performance \n",
    "    \n",
    "     \n",
    "    return X_plus\n",
    "\n",
    "X_feat = apply_feature_eng(X)\n",
    "print(X_feat.shape)\n",
    "X_feat_train = apply_feature_eng(X_train)\n",
    "X_feat_test = apply_feature_eng(X_test)\n",
    "\n",
    "LOSS_FN = compute_correctness\n",
    "LOSS_GREATER_IS_BETTER = True\n",
    "\n",
    "loss_test = ridge_lambda_cv(y_train, X_feat_train, compute_correctness, LAMBDA_SPACE)[1]\n",
    "best_lambda = get_best_parameter(loss_test, LAMBDA_SPACE, LOSS_GREATER_IS_BETTER)\n",
    "\n",
    "best_w = ridge_regression(y, X_feat, best_lambda)\n",
    "y_test_values = predict_values(best_w, X_feat_test)\n",
    "y_hat_test = predict(y_test_values, 0)\n",
    "performance_test = compute_correctness(y_test, y_hat_test)\n",
    "\n",
    "print('Best lambda: {lambda_}\\nPerformance in test set: {pf_test}'\n",
    "      .format(lambda_=best_lambda, pf_test=round(performance_test, 3)))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "def apply_feature_eng(X):\n",
    "\n",
    "    X_plus = copy.deepcopy(X)\n",
    "    \n",
    "    X_plus = replace_nan_by_median(X, -999)\n",
    "    \n",
    "    X_plus = new_transformations(X_plus)\n",
    "    \n",
    "    X_plus = (X_plus - X_plus.mean(axis=0)) / X_plus.std(axis=0)\n",
    "   \n",
    "    X_plus = build_advanced_poly(X_plus, 2)\n",
    "    \n",
    "#     dummy_cols = {'PRI_jet_num': [1, 2, 3, 4]}\n",
    "#     for c in dummy_cols:\n",
    "#         X_plus = dummyrize(X_plus, col_names.index(c), dummy_cols[c]) # decrese performance \n",
    "    \n",
    "     \n",
    "    return X_plus\n",
    "\n",
    "X_feat = apply_feature_eng(X)\n",
    "print(X_feat.shape)\n",
    "X_feat_train = apply_feature_eng(X_train)\n",
    "X_feat_test = apply_feature_eng(X_test)\n",
    "\n",
    "LOSS_FN = compute_correctness\n",
    "LOSS_GREATER_IS_BETTER = True\n",
    "\n",
    "loss_test = ridge_lambda_cv(y_train, X_feat_train, compute_correctness, LAMBDA_SPACE)[1]\n",
    "best_lambda = get_best_parameter(loss_test, LAMBDA_SPACE, LOSS_GREATER_IS_BETTER)\n",
    "\n",
    "best_w = ridge_regression(y, X_feat, best_lambda)\n",
    "y_test_values = predict_values(best_w, X_feat_test)\n",
    "\n",
    "y_hat_test = predict(y_test_values, 0)\n",
    "performance_test = compute_correctness(y_test, y_hat_test)\n",
    "\n",
    "print('Best lambda: {lambda_}\\nPerformance in test set: {pf_test}'\n",
    "      .format(lambda_=best_lambda, pf_test=round(performance_test, 3)))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `compute_correctness` as loss function to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
