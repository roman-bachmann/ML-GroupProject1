{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mlcomp import *\n",
    "from mlcomp.config import DATA_PATH\n",
    "from mlcomp.feature_eng import build_advanced_poly, build_simple_poly, standardize, replace_nan_by_median\n",
    "from mlcomp.helpers import split_data, compute_rmse, predict_labels\n",
    "from mlcomp.performance import eval_correctness\n",
    "from mlcomp.data import load_csv_data, create_csv_submission\n",
    "from mlcomp.models import ridge_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higgs Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_visualization(lambds, mse_tr, mse_te):\n",
    "    \"\"\"visualization the curves of mse_tr and mse_te.\"\"\"\n",
    "    plt.semilogx(lambds, mse_tr, marker=\".\", color='b', label='train error')\n",
    "    plt.semilogx(lambds, mse_te, marker=\".\", color='r', label='test error')\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"rmse\")\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"cross_validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def get_train_indices(k_indices, k):\n",
    "    train_indices = np.array([])\n",
    "    for i in range(k_indices.shape[0]):\n",
    "        if (i != k-1):\n",
    "            train_indices = np.hstack((train_indices, k_indices[i]))\n",
    "    return train_indices.astype(int)\n",
    "\n",
    "def cross_validation_step(yb, tx, k_indices, k, lambda_):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    train_indices = get_train_indices(k_indices, k)\n",
    "    x_train = tx[train_indices]\n",
    "    y_train = yb[train_indices]\n",
    "    x_test = tx[k_indices[k-1]]\n",
    "    y_test = yb[k_indices[k-1]]\n",
    "    \n",
    "    weights, rmse = ridge_regression(y_train, x_train, lambda_)\n",
    "    \n",
    "    loss_tr = compute_rmse(y_train, x_train, weights)\n",
    "    loss_te = compute_rmse(y_test, x_test, weights)\n",
    "    \n",
    "    return loss_tr[0][0], loss_te[0][0]\n",
    "\n",
    "def cross_validation(yb, tx, k_fold, seed=1):\n",
    "    lambdas = np.logspace(-4, 0, 30)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(yb, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    best_rmse_te = float(\"inf\")\n",
    "    best_ind = 0\n",
    "    \n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        avg_loss_tr = 0\n",
    "        avg_loss_te = 0\n",
    "        for k in range(1, k_fold+1):\n",
    "            loss_tr, loss_te = cross_validation_step(yb, tx, k_indices, k, lambda_)\n",
    "            avg_loss_tr += loss_tr\n",
    "            avg_loss_te += loss_te\n",
    "        rmse_tr.append(avg_loss_tr/k_fold)\n",
    "        rmse_te.append(avg_loss_te/k_fold)\n",
    "        if (rmse_te[ind] < best_rmse_te):\n",
    "            best_rmse_te = rmse_te[ind]\n",
    "            best_ind = ind\n",
    "        print(\"lambda={l:.9f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "               l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "    \n",
    "    cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "    return lambdas[best_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental functions\n",
    "\n",
    "All of these functions can be used experimentally to, in one way or the other, improve the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sorted_correlations(yb, tx):\n",
    "    \"\"\"Returns correlations of each input dimension with the labels,\n",
    "    as well as sorted indices of columns with strongest correlations.\"\"\"\n",
    "    cov_mat =  np.corrcoef(yb.T, tx.T)\n",
    "    corr_abs = abs(cov_mat[1:,0])\n",
    "    sorted_idxs = np.argsort(corr_abs)\n",
    "    return corr_abs, sorted_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "yb, input_data, ids = load_csv_data(TRAIN_PATH, sub_sample=False)\n",
    "yb = yb.reshape((yb.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_data.shape, yb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data to more useable data, by replacing NaN's by the column mean and creating a polynomial base expansion.\n",
    "\n",
    "By previous data analysis, important_cols are selected to be the few \"most influencial\" features. We use only those few weights in the polynomial base expansion for computational efficiency.\n",
    "\n",
    "| Index | Feature                   |\n",
    "|-------|---------------------------|\n",
    "|  0    | DER_mass_MMC              |\n",
    "| 1     | DER_mass_traverse_met_lep |\n",
    "| 2     | DER_mass_vis              |\n",
    "| 13    | PRI_tau_pt                |\n",
    "| 11    | DER_met_phi_centrality    |\n",
    "| 10    | DER_pt_ratio_lep_tau      |\n",
    "| 7     | DER_deltar_tau_lep        |\n",
    "| 19    | PRI_met                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#important_cols = [0, 1, 2, 7, 10, 11, 13, 19] # forrest\n",
    "#important_cols = [0, 1, 2, 7, 10, 11, 13, 5] # -\n",
    "#important_cols = [0, 2, 7, 1, 11, 13, 5, 9] # (replace 10 by 9)\n",
    "#important_cols = [0, 2, 7, 1, 11, 13, 5, 9, 19] # 82.592 %\n",
    "#important_cols = [0, 2, 7, 1, 11, 13, 5, 9, 19, 10] # 82.7284 %\n",
    "#important_cols = [0, 2, 7, 1, 11, 13, 5, 9, 19, 10, 4] # 82.9896 % best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx = replace_nan_by_median(input_data, -999)\n",
    "\n",
    "corr_abs, sorted_idxs = sorted_correlations(yb, tx)\n",
    "n = 15\n",
    "D = len(sorted_idxs)\n",
    "print(corr_abs, sorted_idxs[:D-n-1:-1])\n",
    "important_cols = sorted_idxs[:D-n-1:-1]\n",
    "\n",
    "degree = 11 # With current implementation, higher than 5 is comp. infeasable, but it gives the best results!\n",
    "\n",
    "x_comb = build_mult_comb(tx, 2, important_cols)\n",
    "tx = np.concatenate((tx[:, important_cols], x_comb), axis = 1)\n",
    "x_poly = build_simple_poly(tx, degree)\n",
    "x_poly = standardize(x_poly)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = split_data(x_poly, yb, ratio=0.99, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = replace_nan_by_median(input_data, -999)\n",
    "#important_cols = [0, 2, 7, 1, 11, 13, 5, 9, 19] # 82.592 %\n",
    "#important_cols = [0, 2, 7, 1, 11, 13, 5, 9, 19, 10] # 82.7284 %\n",
    "#important_cols = [0, 2, 7, 1, 11, 13, 5, 9, 19, 10, 4] # 82.9896 %\n",
    "important_cols = [0, 1, 2, 4, 5, 7, 9, 10, 11, 13, 19]\n",
    "degree = 5\n",
    "x_poly = build_advanced_poly(tx, degree, important_cols)\n",
    "x_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_poly, mean_poly, std_poly = standardize(x_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(x_poly, yb, ratio=0.9, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plots import *\n",
    "\n",
    "def ridge_regression_sim(x_train, y_train, x_test, y_test, seed=1):\n",
    "    lambdas = np.logspace(-5, 0, 10)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    best_rmse_te = float(\"inf\")\n",
    "    best_weights = 0\n",
    "    best_ind = 0\n",
    "    \n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        weights, rmse = ridge_regression(y_train, x_train, lambda_)\n",
    "        \n",
    "        rmse_tr.append(compute_rmse(y_train, x_train, weights))\n",
    "        rmse_te.append(compute_rmse(y_test, x_test, weights))\n",
    "        \n",
    "        if (rmse_te[ind] < best_rmse_te):\n",
    "            best_rmse_te = rmse_te[ind]\n",
    "            best_weights = weights\n",
    "            best_ind = ind\n",
    "        print(\"lambda={l:.9f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "               l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "        \n",
    "    # Plot the obtained results\n",
    "    plot_train_test(rmse_tr, rmse_te, lambdas, 2)\n",
    "        \n",
    "    return lambdas[best_ind], best_weights, rmse_te[best_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_lambda, best_weights, rmse_te = ridge_regression_sim(x_train, y_train, x_test, y_test, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in best lambda from above and get weights\n",
    "weights, rmse = ridge_regression(y_train, x_train, lambda_=best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict labels with found weights and print some useful information about quality of fit\n",
    "y_pred = predict_labels(weights, x_poly)\n",
    "eval_correctness(yb, y_pred, verbose=True)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "rmse_train = compute_rmse(y_train, x_train, weights)\n",
    "rmse_test = compute_rmse(y_test, x_test, weights)\n",
    "print(\"Train RMSE:\", rmse_train, \", Test RMSE:\", rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_fold = 4\n",
    "best_lambda = cross_validation(yb, x_poly, k_fold, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights, rsme = ridge_regression(yb, x_poly, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict labels with found weights and print some useful information about quality of fit\n",
    "y_pred = predict_labels(weights, x_poly)\n",
    "correctness(yb, y_pred, verbose=True)\n",
    "print(\"-----------------\")\n",
    "print(rsme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different cutoff value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_values(weights, X):\n",
    "    return np.dot(X, weights)\n",
    "\n",
    "def predict(y_values, cutoff):\n",
    "    labels = np.empty(len(y_values))\n",
    "    labels[y_values <= cutoff] = -1\n",
    "    labels[y_values > cutoff] = 1\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def correct_by_cutoff(y_true, y_pred, search_space):\n",
    "    labels = list(map(lambda c: predict(y_pred, c), search_space))\n",
    "    corrects = list(map(lambda l: correctness(y_true, l), labels))\n",
    "    return corrects\n",
    "\n",
    "y_hat_train = predict_values(weights, x_poly)\n",
    "\n",
    "cutoff_search_space = np.linspace(-4, 4, retstep=0.01)[0]\n",
    "correctness_by_cutoff = correct_by_cutoff(yb, y_hat_train, cutoff_search_space)\n",
    "plt.plot(cutoff_search_space, correctness_by_cutoff);\n",
    "\n",
    "best_cutoff = cutoff_search_space[correctness_by_cutoff.index(max(correctness_by_cutoff))]\n",
    "print('Best cutoff in train: {}'.format(best_cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Correctness in train with cutoff 0: {}'.format(correctness(y_train, predict(y_hat_train, 0))))\n",
    "print('Correctness in train with best cutoff: {}'.format(correctness(y_train, predict(y_hat_train, best_cutoff))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and transform test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = \"../data/test.csv\"\n",
    "yb_test, input_data_test, ids_test = load_csv_data(test_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data_test = replace_nan_by_median(input_data_test, -999)\n",
    "#input_data_test = (input_data_test - input_data_test.min(0)) / input_data_test.ptp(0) # normalize\n",
    "x_submit_poly = build_advanced_poly(input_data_test, degree, important_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "input_data_test = replace_nan_by_median(input_data_test, -999)\n",
    "submit_poly = PolynomialFeatures(degree)\n",
    "x_submit_poly = submit_poly.fit_transform(input_data_test[:, important_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_test_pred = predict(predict_values(weights, x_submit_poly), 0)\n",
    "y_test_pred = predict_labels(weights, x_submit_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions of test data in csv file, ready for the upload on kaggle\n",
    "create_csv_submission(ids_test, y_test_pred, \"test_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
